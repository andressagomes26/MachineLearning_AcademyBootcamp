{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e5a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\andressa.moreira\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc36c4",
   "metadata": {},
   "source": [
    "## Classificação de imagens de tempo\n",
    "\n",
    "**Classificação de Imagens**\n",
    "\n",
    "> Classificação de imagens de tempo utilizando técnicas clássicas de Processamento Digital de Imagens e treinar classificadores para predição dos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a71d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Módulos necessários\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from skimage.measure import regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.preprocessing import MaxAbsScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e105c9",
   "metadata": {},
   "source": [
    "- **Preparando o dataset**\n",
    "\n",
    "> Neste primeiro momento há necessidade de observar as imagens do dataset e organizá-las em uma estrutura de dados adequada para que seus atributos possam ser extraídos. há então a necessidade de carregar o conjunto de imagens via código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43b3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datadir, classes, img_size=100):\n",
    "    training_data = []\n",
    "    label = []\n",
    "    for classe in range(len(classes)):\n",
    "        path = os.path.join(datadir, classes[classe])\n",
    "        shufled_list  = list(os.listdir(path))\n",
    "        shuffle(shufled_list)\n",
    "        for img in shufled_list:\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            #img_array = cv2.resize(img_array, (img_size, img_size)).flatten()\n",
    "            \n",
    "            training_data.append(img_array)\n",
    "            label.append(classe)\n",
    "            \n",
    "    return training_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd87d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = load_data('dataset/tempo', ['cloudy','rain','shine','sunrise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef085a86",
   "metadata": {},
   "source": [
    "- O código acima realiza a implementação de uma função que recebe 3 argumentos: o diretório que contem as pastas das imagens, uma lista de string que contém o nome das classes que devem ser reconhecidas e um parâmetro default que é o  tamanho da imagem que será utilizado em todo o processo. \n",
    "\n",
    "\n",
    "- São definidas duas listas vazias training_data e label. Em ***training_data*** serão armazenadas as imagens e em ***label*** serão definidos números que representam cada classe. Deste modo, é possível saber a classe da imagem que estiver na posição 5 da lista training_data observando o número contido da quinta posição da lista label.\n",
    "\n",
    "- Um loop for é realizado para iterar sobre as possíveis classes. Assim a variável classe, definida no loop, poderá assumir valores variando de  0 até 3, em que 0 representa classe **'cloudy'** e 3 representa a classe **'sunrise'**. Na variável path é armazenada a string que contem o caminho para pasta de imagens da classe específica, conforme iteração do loop for e na estrutura shufled_list são contidas strings que são os caminhos de cada imagem da classe, já com um primeiro embaralhamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a4413",
   "metadata": {},
   "source": [
    "### Extração de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b27f06",
   "metadata": {},
   "source": [
    "> Definir dois métodos para obter uma imagem de entrada e convertê-la em um vetor de recursos ou uma lista de números que quantificam o conteúdo de uma imagem:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d4f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98facc85",
   "metadata": {},
   "source": [
    "> A função aceita uma imagem de entrada e constrói um histograma de cores para caracterizar a distribuição de cores da imagem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d099e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "def extract_color_histogram(image):\n",
    "    imgSuavizada = cv2.GaussianBlur(image, (13,13), 3)\n",
    "    imgDetalhes = 3 * cv2.subtract(image, imgSuavizada)\n",
    "    imgRealcada = cv2.add(image, imgDetalhes)\n",
    "    # realizar a equalização do histograma\n",
    "    image_eq = exposure.equalize_hist(imgRealcada)\n",
    "    # determinar a media do valor dos pixels que ocorrem na imagem  equalizada\n",
    "    img_mean_eq = np.mean(image_eq)*255\n",
    "    return image_eq.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b7fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andressa.moreira\\Anaconda3\\lib\\site-packages\\skimage\\_shared\\utils.py:394: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel, or set channel_axis.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rawImages = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def features_extraction(images):\n",
    "    features_list = []\n",
    "    for image in images:\n",
    "        #print(image.shape)\n",
    "        hist = extract_color_histogram(image)\n",
    "        features.append(hist)\n",
    "    return features\n",
    "\n",
    "features = features_extraction(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9474d0",
   "metadata": {},
   "source": [
    "- **Treinamento e Teste dos Classificadores.**\n",
    "> A variável features possui as os atributos extraídos das imagens. Neste contexto, a função gen_classifiers é iamplementada para retornar testes em 7 classificadores: Random Forest, MLP, KNN, SGDC, SVM, Árvore de decisão e Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdcf31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_svm_model(train_data,label_train_data,test_data):\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_SGDC_model(train_data,label_train_data,test_data):\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=200)\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_naive_bayes_model(train_data,label_train_data,test_data):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_data, label_train_data)\n",
    "    predicted = gnb.predict(test_data)\n",
    "    return predicted\n",
    "def generate_decision_tree_model(train_data,label_train_data,test_data):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_random_forest_model(X_train, y_train,test_data):\n",
    "    rfc = RandomForestClassifier(criterion= 'entropy', max_depth= 8, max_features='auto', n_estimators=200)\n",
    "    rfc.fit(X_train,y_train)\n",
    "    predicted = rfc.predict(test_data)\n",
    "    return predicted\n",
    "def generate_MLP_model(X_train, y_train,test_data):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(test_data)\n",
    "    return predicted\n",
    "def generate_knn_model(train_data,label_train_data,test_data):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(train_data,label_train_data)\n",
    "    predicted = knn.predict(test_data)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61779ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_classifiers(train_data,label_train_data,test_data):\n",
    "    return generate_knn_model(train_data,label_train_data,test_data),\\\n",
    "    generate_MLP_model(train_data,label_train_data,test_data),\\\n",
    "    generate_SGDC_model(train_data,label_train_data,test_data),\\\n",
    "    generate_svm_model(train_data,label_train_data,test_data),\\\n",
    "    generate_decision_tree_model(train_data,label_train_data,test_data),\\\n",
    "    generate_naive_bayes_model(train_data,label_train_data,test_data),\\\n",
    "    generate_random_forest_model(train_data,label_train_data,test_data),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0702f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.3)\n",
    "results = gen_classifiers(X_train, y_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aefc7de",
   "metadata": {},
   "source": [
    "- A função divide o conjunto de atributos e labels em conjuntos de treino e teste para garantirmos que o processo de treinamento seja realizado com dados distintos dos que vão ser testados por cada classificador.\n",
    "\n",
    "- Deste modo, a função gen_classifiers recebe os atributos de treinamento, as labels dos atributos de treinamento e os atribiutos de teste e retorna um array de valores que indicam os resultados dos testes de cada classificador. Cada classificador é inicializado com um objeto específico. Após a inicialização é realizado o comando fit para treinar o classificadorque recebe os atribiutos de treinamento e as labels dos atributos. Após o treinamento é realizado o comando predict para testar se o classificador realiza uma predição correta de atributos que não foram utilizados no conjunto de treinamento. A variável predicted é um vetor em que cada elemento do vetor é um valor que indica a classe a qual o atributo pertence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8cddd",
   "metadata": {},
   "source": [
    "- **Avaliação dos classificadores**\n",
    "> A biblioteca sklearn possui funções que auxiliam a medir quantitativamente o desempenho do classificador. A acurácia do classificador pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e401e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc KNN: 0.7032640949554896\n",
      "Acc MLP: 0.8249258160237388\n",
      "Acc SGDC: 0.7477744807121661\n",
      "Acc svm: 0.798219584569733\n",
      "Acc decision_tree: 0.6083086053412463\n",
      "Acc naive_bayes: 0.7388724035608308\n",
      "Acc random_forest: 0.8249258160237388\n"
     ]
    }
   ],
   "source": [
    "acc_knn = metrics.accuracy_score(y_test, results[0])\n",
    "acc_MLP = metrics.accuracy_score(y_test, results[1])\n",
    "acc_SGDC = metrics.accuracy_score(y_test, results[2])\n",
    "acc_svm = metrics.accuracy_score(y_test, results[3])\n",
    "acc_decision_tree = metrics.accuracy_score(y_test, results[4])\n",
    "acc_naive_bayes = metrics.accuracy_score(y_test, results[5])\n",
    "acc_random_forest = metrics.accuracy_score(y_test, results[6])\n",
    "\n",
    "print(\"Acc KNN: {}\".format(acc_knn))\n",
    "print(\"Acc MLP: {}\".format(acc_MLP))\n",
    "print(\"Acc SGDC: {}\".format(acc_SGDC))\n",
    "print(\"Acc svm: {}\".format(acc_svm))\n",
    "print(\"Acc decision_tree: {}\".format(acc_decision_tree))\n",
    "print(\"Acc naive_bayes: {}\".format(acc_naive_bayes))\n",
    "print(\"Acc random_forest: {}\".format(acc_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7296f",
   "metadata": {},
   "source": [
    "VP = Verdadeiro positivo - objeto pertence a classe A e foi classificado na classe A\n",
    "\n",
    "VN = Verdadeiro negativo - objeto não pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "FP = Falso positivo - objeto não pertence a classe A e foi classificado na classe A\n",
    "\n",
    "FN = Falso negativo - objeto pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "A sensibilidade/revocação/recall do classificador, por classe,  pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "520155f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "precision KNN: [0.67391304 1.         0.69879518 0.67391304]\n",
      "precision MLP: [0.73626374 0.84126984 0.75       0.96842105]\n",
      "precision SGDC: [0.63265306 0.85416667 0.67045455 0.87378641]\n",
      "precision svm: [0.7032967  0.85245902 0.73255814 0.90909091]\n",
      "precision decision_tree: [0.61842105 0.49275362 0.54347826 0.74      ]\n",
      "precision naive_bayes: [0.64835165 0.64556962 0.69047619 0.97590361]\n",
      "precision random_forest: [0.75555556 0.81967213 0.79761905 0.91176471]\n",
      "recall\n",
      "precision KNN: [0.63917526 0.33802817 0.78378378 0.97894737]\n",
      "precision MLP: [0.69072165 0.74647887 0.89189189 0.96842105]\n",
      "precision SGDC: [0.63917526 0.57746479 0.7972973  0.94736842]\n",
      "precision svm: [0.65979381 0.73239437 0.85135135 0.94736842]\n",
      "precision decision_tree: [0.48453608 0.47887324 0.67567568 0.77894737]\n",
      "precision naive_bayes: [0.60824742 0.71830986 0.78378378 0.85263158]\n",
      "precision random_forest: [0.70103093 0.70422535 0.90540541 0.97894737]\n",
      "f1_score\n",
      "precision KNN: [0.65608466 0.50526316 0.7388535  0.79828326]\n",
      "precision MLP: [0.71276596 0.79104478 0.81481481 0.96842105]\n",
      "precision SGDC: [0.63589744 0.68907563 0.72839506 0.90909091]\n",
      "precision svm: [0.68085106 0.78787879 0.7875     0.92783505]\n",
      "precision decision_tree: [0.5433526  0.48571429 0.60240964 0.75897436]\n",
      "precision naive_bayes: [0.62765957 0.68       0.73417722 0.91011236]\n",
      "precision random_forest: [0.72727273 0.75757576 0.84810127 0.94416244]\n"
     ]
    }
   ],
   "source": [
    "modelo = [\"KNN\", \"MLP\", \"SGDC\", \"svm\", \"decision_tree\", \"naive_bayes\", \"random_forest\"]\n",
    "\n",
    "def precision(y_test, results):\n",
    "    return metrics.precision_score(y_test, results, average=None)\n",
    "def recall(y_test, results):\n",
    "    return metrics.recall_score(y_test, results, average=None)\n",
    "def f1_score(y_test, results):\n",
    "    return metrics.f1_score(y_test, results, average=None)\n",
    "\n",
    "def printScore(modelo, avali):\n",
    "    for i in range(0, len(modelo)):\n",
    "        print(\"precision {}: {}\".format(modelo[i], avali(y_test, results[i])))\n",
    "\n",
    "print(\"Precision\")\n",
    "printScore(modelo, precision)\n",
    "print(\"recall\")\n",
    "printScore(modelo, recall)\n",
    "print(\"f1_score\")\n",
    "printScore(modelo, f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
