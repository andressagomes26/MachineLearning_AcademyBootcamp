{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e5a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\andressa.moreira\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc36c4",
   "metadata": {},
   "source": [
    "## Classificação de imagens de tempo\n",
    "\n",
    "**Classificação de Imagens**\n",
    "\n",
    "> Classificação de imagens de tempo utilizando técnicas clássicas de Processamento Digital de Imagens e treinar classificadores para predição dos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a71d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Módulos necessários\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from skimage.measure import regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.preprocessing import MaxAbsScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e105c9",
   "metadata": {},
   "source": [
    "- **Preparando o dataset**\n",
    "\n",
    "> Neste primeiro momento há necessidade de observar as imagens do dataset e organizá-las em uma estrutura de dados adequada para que seus atributos possam ser extraídos. há então a necessidade de carregar o conjunto de imagens via código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43b3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datadir, classes, img_size=100):\n",
    "    training_data = []\n",
    "    label = []\n",
    "    for classe in range(len(classes)):\n",
    "        path = os.path.join(datadir, classes[classe])\n",
    "        shufled_list  = list(os.listdir(path))\n",
    "        shuffle(shufled_list)\n",
    "        for img in shufled_list:\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            #img_array = cv2.resize(img_array, (img_size, img_size)).flatten()\n",
    "            \n",
    "            training_data.append(img_array)\n",
    "            label.append(classe)\n",
    "            \n",
    "    return training_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd87d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = load_data('dataset/tempo', ['cloudy','rain','shine','sunrise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe73c95",
   "metadata": {},
   "source": [
    "- O código acima realiza a implementação de uma função que recebe 3 argumentos: o diretório que contem as pastas das imagens, uma lista de string que contém o nome das classes que devem ser reconhecidas e um parâmetro default que é o  tamanho da imagem que será utilizado em todo o processo. \n",
    "\n",
    "\n",
    "- São definidas duas listas vazias training_data e label. Em ***training_data*** serão armazenadas as imagens e em ***label*** serão definidos números que representam cada classe. Deste modo, é possível saber a classe da imagem que estiver na posição 5 da lista training_data observando o número contido da quinta posição da lista label.\n",
    "\n",
    "- Um loop for é realizado para iterar sobre as possíveis classes. Assim a variável classe, definida no loop, poderá assumir valores variando de  0 até 3, em que 0 representa classe **'cloudy'** e 3 representa a classe **'sunrise'**. Na variável path é armazenada a string que contem o caminho para pasta de imagens da classe específica, conforme iteração do loop for e na estrutura shufled_list são contidas strings que são os caminhos de cada imagem da classe, já com um primeiro embaralhamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceae5d0",
   "metadata": {},
   "source": [
    "### Extração de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b27f06",
   "metadata": {},
   "source": [
    "> Definir dois métodos para obter uma imagem de entrada e convertê-la em um vetor de recursos ou uma lista de números que quantificam o conteúdo de uma imagem:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5503c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83714a07",
   "metadata": {},
   "source": [
    "> A função aceita uma imagem de entrada e constrói um histograma de cores para caracterizar a distribuição de cores da imagem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9bc773ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "def extract_color_histogram(image):\n",
    "    imgSuavizada = cv2.GaussianBlur(image, (13,13), 3)\n",
    "    imgDetalhes = 3 * cv2.subtract(image, imgSuavizada)\n",
    "    imgRealcada = cv2.add(image, imgDetalhes)\n",
    "    # realizar a equalização do histograma\n",
    "    image_eq = exposure.equalize_hist(imgRealcada)\n",
    "    # determinar a media do valor dos pixels que ocorrem na imagem  equalizada\n",
    "    img_mean_eq = np.mean(image_eq)*255\n",
    "    return image_eq.flatten()\n",
    "\n",
    "def extract_color_histogram2(image):\n",
    "    imgSuavizada = cv2.GaussianBlur(image, (13,13), 3)\n",
    "    imgDetalhes = 3 * cv2.subtract(image, imgSuavizada)\n",
    "    imgRealcada = cv2.add(image, imgDetalhes)\n",
    "    #hsv = cv2.cvtColor(imgRealcada, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    hsv = cv2.cvtColor(imgRealcada, cv2.COLOR_BGR2HSV)\n",
    "    #hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [ 0 , 256 , 0 , 256 , 0 , 256 ])\n",
    "    hist_norm = cv2.normalize(hist)\n",
    "    \n",
    "    return hist_norm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8edb325e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'normalize'\n> Overload resolution failed:\n>  - normalize() missing required argument 'dst' (pos 2)\n>  - normalize() missing required argument 'dst' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [116]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(hist)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\n\u001b[1;32m---> 13\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [116]\u001b[0m, in \u001b[0;36mfeatures_extraction\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      6\u001b[0m features_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#print(image.shape)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mextract_color_histogram2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(hist)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "Input \u001b[1;32mIn [115]\u001b[0m, in \u001b[0;36mextract_color_histogram2\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [0, 180, 0, 256, 0, 256])\u001b[39;00m\n\u001b[0;32m     20\u001b[0m hist \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcHist([hsv], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), [ \u001b[38;5;241m0\u001b[39m , \u001b[38;5;241m256\u001b[39m , \u001b[38;5;241m0\u001b[39m , \u001b[38;5;241m256\u001b[39m , \u001b[38;5;241m0\u001b[39m , \u001b[38;5;241m256\u001b[39m ])\n\u001b[1;32m---> 21\u001b[0m hist_norm \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hist_norm\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'normalize'\n> Overload resolution failed:\n>  - normalize() missing required argument 'dst' (pos 2)\n>  - normalize() missing required argument 'dst' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "rawImages = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def features_extraction(images):\n",
    "    features_list = []\n",
    "    for image in images:\n",
    "        #print(image.shape)\n",
    "        hist = extract_color_histogram2(image)\n",
    "        features.append(hist)\n",
    "    return features\n",
    "\n",
    "features = features_extraction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2afa99f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,  17.,  10.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   6.,   8.,   2.,   0.,   2.,   0.,   0.,\n",
       "         0.,   7.,   9.,   9.,   0.,  16.,   0.,   1.,   0.,   7.,  34.,\n",
       "        39.,   5., 354.,   1.,   2.,   2.,  27.,  50., 157.,  44., 995.,\n",
       "       272.,  13.,   1.,  61.,  88., 209., 119., 234., 861., 431.,  75.,\n",
       "       208., 457., 595., 536., 425., 929., 922., 653., 929.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   1.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   8.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  11.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  17.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   5.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   5.,   2.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  10.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         8.,  13.,   9.,   0.,   0.,   2.,   0.,   0.,   5.,  13.,   8.,\n",
       "        11.,   3.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "         0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9474d0",
   "metadata": {},
   "source": [
    "- **Treinamento e Teste dos Classificadores.**\n",
    "> A variável features possui as os atributos extraídos das imagens. Neste contexto, a função gen_classifiers é iamplementada para retornar testes em 7 classificadores: Random Forest, MLP, KNN, SGDC, SVM, Árvore de decisão e Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdcf31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_svm_model(train_data,label_train_data,test_data):\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_SGDC_model(train_data,label_train_data,test_data):\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=200)\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_naive_bayes_model(train_data,label_train_data,test_data):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_data, label_train_data)\n",
    "    predicted = gnb.predict(test_data)\n",
    "    return predicted\n",
    "def generate_decision_tree_model(train_data,label_train_data,test_data):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_random_forest_model(X_train, y_train,test_data):\n",
    "    rfc = RandomForestClassifier(criterion= 'entropy', max_depth= 8, max_features='auto', n_estimators=200)\n",
    "    rfc.fit(X_train,y_train)\n",
    "    predicted = rfc.predict(test_data)\n",
    "    return predicted\n",
    "def generate_MLP_model(X_train, y_train,test_data):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(test_data)\n",
    "    return predicted\n",
    "def generate_knn_model(train_data,label_train_data,test_data):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(train_data,label_train_data)\n",
    "    predicted = knn.predict(test_data)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "61779ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_classifiers(train_data,label_train_data,test_data):\n",
    "    return generate_knn_model(train_data,label_train_data,test_data),\\\n",
    "    generate_MLP_model(train_data,label_train_data,test_data),\\\n",
    "    generate_SGDC_model(train_data,label_train_data,test_data),\\\n",
    "    generate_svm_model(train_data,label_train_data,test_data),\\\n",
    "    generate_decision_tree_model(train_data,label_train_data,test_data),\\\n",
    "    generate_naive_bayes_model(train_data,label_train_data,test_data),\\\n",
    "    generate_random_forest_model(train_data,label_train_data,test_data),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f0702f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.3)\n",
    "results = gen_classifiers(X_train, y_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aefc7de",
   "metadata": {},
   "source": [
    "- A função divide o conjunto de atributos e labels em conjuntos de treino e teste para garantirmos que o processo de treinamento seja realizado com dados distintos dos que vão ser testados por cada classificador.\n",
    "\n",
    "- Deste modo, a função gen_classifiers recebe os atributos de treinamento, as labels dos atributos de treinamento e os atribiutos de teste e retorna um array de valores que indicam os resultados dos testes de cada classificador. Cada classificador é inicializado com um objeto específico. Após a inicialização é realizado o comando fit para treinar o classificadorque recebe os atribiutos de treinamento e as labels dos atributos. Após o treinamento é realizado o comando predict para testar se o classificador realiza uma predição correta de atributos que não foram utilizados no conjunto de treinamento. A variável predicted é um vetor em que cada elemento do vetor é um valor que indica a classe a qual o atributo pertence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8cddd",
   "metadata": {},
   "source": [
    "- **Avaliação dos classificadores**\n",
    "> A biblioteca sklearn possui funções que auxiliam a medir quantitativamente o desempenho do classificador. A acurácia do classificador pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "37e401e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc KNN: 0.8635014836795252\n",
      "Acc MLP: 0.8456973293768546\n",
      "Acc SGDC: 0.8605341246290801\n",
      "Acc svm: 0.8605341246290801\n",
      "Acc decision_tree: 0.8041543026706232\n",
      "Acc naive_bayes: 0.7952522255192879\n",
      "Acc random_forest: 0.887240356083086\n"
     ]
    }
   ],
   "source": [
    "acc_knn = metrics.accuracy_score(y_test, results[0])\n",
    "acc_MLP = metrics.accuracy_score(y_test, results[1])\n",
    "acc_SGDC = metrics.accuracy_score(y_test, results[2])\n",
    "acc_svm = metrics.accuracy_score(y_test, results[3])\n",
    "acc_decision_tree = metrics.accuracy_score(y_test, results[4])\n",
    "acc_naive_bayes = metrics.accuracy_score(y_test, results[5])\n",
    "acc_random_forest = metrics.accuracy_score(y_test, results[6])\n",
    "\n",
    "print(\"Acc KNN: {}\".format(acc_knn))\n",
    "print(\"Acc MLP: {}\".format(acc_MLP))\n",
    "print(\"Acc SGDC: {}\".format(acc_SGDC))\n",
    "print(\"Acc svm: {}\".format(acc_svm))\n",
    "print(\"Acc decision_tree: {}\".format(acc_decision_tree))\n",
    "print(\"Acc naive_bayes: {}\".format(acc_naive_bayes))\n",
    "print(\"Acc random_forest: {}\".format(acc_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7296f",
   "metadata": {},
   "source": [
    "VP = Verdadeiro positivo - objeto pertence a classe A e foi classificado na classe A\n",
    "\n",
    "VN = Verdadeiro negativo - objeto não pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "FP = Falso positivo - objeto não pertence a classe A e foi classificado na classe A\n",
    "\n",
    "FN = Falso negativo - objeto pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "A sensibilidade/revocação/recall do classificador, por classe,  pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "520155f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "precision KNN: [0.859375   0.70588235 0.83695652 0.98230088]\n",
      "precision MLP: [0.79166667 0.66666667 0.85882353 0.97368421]\n",
      "precision SGDC: [0.73       0.76785714 0.91891892 0.99065421]\n",
      "precision svm: [0.75       0.72307692 0.91891892 0.99090909]\n",
      "precision decision_tree: [0.68367347 0.71153846 0.80519481 0.95454545]\n",
      "precision naive_bayes: [0.62831858 0.74358974 0.85915493 0.93859649]\n",
      "precision random_forest: [0.81927711 0.875      0.85555556 0.96551724]\n",
      "recall\n",
      "precision KNN: [0.6547619  0.81355932 0.9625     0.97368421]\n",
      "precision MLP: [0.67857143 0.74576271 0.9125     0.97368421]\n",
      "precision SGDC: [0.86904762 0.72881356 0.85       0.92982456]\n",
      "precision svm: [0.78571429 0.79661017 0.85       0.95614035]\n",
      "precision decision_tree: [0.79761905 0.62711864 0.775      0.92105263]\n",
      "precision naive_bayes: [0.8452381  0.49152542 0.7625     0.93859649]\n",
      "precision random_forest: [0.80952381 0.71186441 0.9625     0.98245614]\n",
      "f1_score\n",
      "precision KNN: [0.74324324 0.75590551 0.89534884 0.97797357]\n",
      "precision MLP: [0.73076923 0.704      0.88484848 0.97368421]\n",
      "precision SGDC: [0.79347826 0.74782609 0.88311688 0.95927602]\n",
      "precision svm: [0.76744186 0.75806452 0.88311688 0.97321429]\n",
      "precision decision_tree: [0.73626374 0.66666667 0.78980892 0.9375    ]\n",
      "precision naive_bayes: [0.72081218 0.59183673 0.80794702 0.93859649]\n",
      "precision random_forest: [0.81437126 0.78504673 0.90588235 0.97391304]\n"
     ]
    }
   ],
   "source": [
    "modelo = [\"KNN\", \"MLP\", \"SGDC\", \"svm\", \"decision_tree\", \"naive_bayes\", \"random_forest\"]\n",
    "\n",
    "def precision(y_test, results):\n",
    "    return metrics.precision_score(y_test, results, average=None)\n",
    "def recall(y_test, results):\n",
    "    return metrics.recall_score(y_test, results, average=None)\n",
    "def f1_score(y_test, results):\n",
    "    return metrics.f1_score(y_test, results, average=None)\n",
    "\n",
    "def printScore(modelo, avali):\n",
    "    for i in range(0, len(modelo)):\n",
    "        print(\"precision {}: {}\".format(modelo[i], avali(y_test, results[i])))\n",
    "\n",
    "print(\"Precision\")\n",
    "printScore(modelo, precision)\n",
    "print(\"recall\")\n",
    "printScore(modelo, recall)\n",
    "print(\"f1_score\")\n",
    "printScore(modelo, f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
