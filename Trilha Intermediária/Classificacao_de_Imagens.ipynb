{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e5a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\andressa.moreira\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc36c4",
   "metadata": {},
   "source": [
    "## Classificação de imagens de tempo\n",
    "\n",
    "**Classificação de Imagens**\n",
    "\n",
    "> Classificação de imagens de tempo utilizando técnicas clássicas de Processamento Digital de Imagens e treinar classificadores para predição dos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a71d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Módulos necessários\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from skimage.measure import regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.preprocessing import MaxAbsScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e105c9",
   "metadata": {},
   "source": [
    "- **Preparando o dataset**\n",
    "\n",
    "> Neste primeiro momento há necessidade de observar as imagens do dataset e organizá-las em uma estrutura de dados adequada para que seus atributos possam ser extraídos. há então a necessidade de carregar o conjunto de imagens via código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43b3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datadir, classes, img_size=100):\n",
    "    training_data = []\n",
    "    label = []\n",
    "    for classe in range(len(classes)):\n",
    "        path = os.path.join(datadir, classes[classe])\n",
    "        shufled_list  = list(os.listdir(path))\n",
    "        shuffle(shufled_list)\n",
    "        for img in shufled_list:\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            #img_array = cv2.resize(img_array, (img_size, img_size)).flatten()\n",
    "            \n",
    "            training_data.append(img_array)\n",
    "            label.append(classe)\n",
    "            \n",
    "    return training_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd87d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = load_data('dataset/tempo', ['cloudy','rain','shine','sunrise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f1839",
   "metadata": {},
   "source": [
    "- O código acima realiza a implementação de uma função que recebe 3 argumentos: o diretório que contem as pastas das imagens, uma lista de string que contém o nome das classes que devem ser reconhecidas e um parâmetro default que é o  tamanho da imagem que será utilizado em todo o processo. \n",
    "\n",
    "\n",
    "- São definidas duas listas vazias training_data e label. Em ***training_data*** serão armazenadas as imagens e em ***label*** serão definidos números que representam cada classe. Deste modo, é possível saber a classe da imagem que estiver na posição 5 da lista training_data observando o número contido da quinta posição da lista label.\n",
    "\n",
    "- Um loop for é realizado para iterar sobre as possíveis classes. Assim a variável classe, definida no loop, poderá assumir valores variando de  0 até 3, em que 0 representa classe **'cloudy'** e 3 representa a classe **'sunrise'**. Na variável path é armazenada a string que contem o caminho para pasta de imagens da classe específica, conforme iteração do loop for e na estrutura shufled_list são contidas strings que são os caminhos de cada imagem da classe, já com um primeiro embaralhamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b3aa0",
   "metadata": {},
   "source": [
    "### Extração de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b27f06",
   "metadata": {},
   "source": [
    "> Definir dois métodos para obter uma imagem de entrada e convertê-la em um vetor de recursos ou uma lista de números que quantificam o conteúdo de uma imagem:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5c5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f7bad",
   "metadata": {},
   "source": [
    "> A função aceita uma imagem de entrada e constrói um histograma de cores para caracterizar a distribuição de cores da imagem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ddc05c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "def extract_color_histogram(image):\n",
    "    imgSuavizada = cv2.GaussianBlur(image, (13,13), 3)\n",
    "    imgDetalhes = 3 * cv2.subtract(image, imgSuavizada)\n",
    "    imgRealcada = cv2.add(image, imgDetalhes)\n",
    "    # realizar a equalização do histograma\n",
    "    image_eq = exposure.equalize_hist(imgRealcada)\n",
    "    # determinar a media do valor dos pixels que ocorrem na imagem  equalizada\n",
    "    img_mean_eq = np.mean(image_eq)*255\n",
    "    return image_eq.flatten()\n",
    "\n",
    "def extract_color_histogram2(image):\n",
    "    imgSuavizada = cv2.GaussianBlur(image, (13,13), 3)\n",
    "    imgDetalhes = 3 * cv2.subtract(image, imgSuavizada)\n",
    "    imgRealcada = cv2.add(image, imgDetalhes)\n",
    "    #hsv = cv2.cvtColor(imgRealcada, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    hsv = cv2.cvtColor(imgRealcada, cv2.COLOR_BGR2HSV)\n",
    "    #hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [ 0 , 256 , 0 , 256 , 0 , 256 ])\n",
    "    hist_norm = cv2.normalize(hist, hist)\n",
    "    \n",
    "    return hist_norm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8418c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawImages = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def features_extraction(images):\n",
    "    features_list = []\n",
    "    for image in images:\n",
    "        #print(image.shape)\n",
    "        hist = extract_color_histogram2(image)\n",
    "        features.append(hist)\n",
    "    return features\n",
    "\n",
    "features = features_extraction(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9474d0",
   "metadata": {},
   "source": [
    "- **Treinamento e Teste dos Classificadores.**\n",
    "> A variável features possui as os atributos extraídos das imagens. Neste contexto, a função gen_classifiers é iamplementada para retornar testes em 7 classificadores: Random Forest, MLP, KNN, SGDC, SVM, Árvore de decisão e Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fdcf31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_svm_model(train_data,label_train_data,test_data):\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_SGDC_model(train_data,label_train_data,test_data):\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=200)\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_naive_bayes_model(train_data,label_train_data,test_data):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_data, label_train_data)\n",
    "    predicted = gnb.predict(test_data)\n",
    "    return predicted\n",
    "def generate_decision_tree_model(train_data,label_train_data,test_data):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_random_forest_model(X_train, y_train,test_data):\n",
    "    rfc = RandomForestClassifier(criterion= 'entropy', max_depth= 8, max_features='auto', n_estimators=200)\n",
    "    rfc.fit(X_train,y_train)\n",
    "    predicted = rfc.predict(test_data)\n",
    "    return predicted\n",
    "def generate_MLP_model(X_train, y_train,test_data):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(test_data)\n",
    "    return predicted\n",
    "def generate_knn_model(train_data,label_train_data,test_data):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(train_data,label_train_data)\n",
    "    predicted = knn.predict(test_data)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "61779ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_classifiers(train_data,label_train_data,test_data):\n",
    "    return generate_knn_model(train_data,label_train_data,test_data),\\\n",
    "    generate_MLP_model(train_data,label_train_data,test_data),\\\n",
    "    generate_SGDC_model(train_data,label_train_data,test_data),\\\n",
    "    generate_svm_model(train_data,label_train_data,test_data),\\\n",
    "    generate_decision_tree_model(train_data,label_train_data,test_data),\\\n",
    "    generate_naive_bayes_model(train_data,label_train_data,test_data),\\\n",
    "    generate_random_forest_model(train_data,label_train_data,test_data),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f0702f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.3)\n",
    "results = gen_classifiers(X_train, y_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aefc7de",
   "metadata": {},
   "source": [
    "- A função divide o conjunto de atributos e labels em conjuntos de treino e teste para garantirmos que o processo de treinamento seja realizado com dados distintos dos que vão ser testados por cada classificador.\n",
    "\n",
    "- Deste modo, a função gen_classifiers recebe os atributos de treinamento, as labels dos atributos de treinamento e os atribiutos de teste e retorna um array de valores que indicam os resultados dos testes de cada classificador. Cada classificador é inicializado com um objeto específico. Após a inicialização é realizado o comando fit para treinar o classificadorque recebe os atribiutos de treinamento e as labels dos atributos. Após o treinamento é realizado o comando predict para testar se o classificador realiza uma predição correta de atributos que não foram utilizados no conjunto de treinamento. A variável predicted é um vetor em que cada elemento do vetor é um valor que indica a classe a qual o atributo pertence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8cddd",
   "metadata": {},
   "source": [
    "- **Avaliação dos classificadores**\n",
    "> A biblioteca sklearn possui funções que auxiliam a medir quantitativamente o desempenho do classificador. A acurácia do classificador pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "37e401e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc KNN: 0.8367952522255193\n",
      "Acc MLP: 0.857566765578635\n",
      "Acc SGDC: 0.8427299703264095\n",
      "Acc svm: 0.8545994065281899\n",
      "Acc decision_tree: 0.8249258160237388\n",
      "Acc naive_bayes: 0.7774480712166172\n",
      "Acc random_forest: 0.8724035608308606\n"
     ]
    }
   ],
   "source": [
    "acc_knn = metrics.accuracy_score(y_test, results[0])\n",
    "acc_MLP = metrics.accuracy_score(y_test, results[1])\n",
    "acc_SGDC = metrics.accuracy_score(y_test, results[2])\n",
    "acc_svm = metrics.accuracy_score(y_test, results[3])\n",
    "acc_decision_tree = metrics.accuracy_score(y_test, results[4])\n",
    "acc_naive_bayes = metrics.accuracy_score(y_test, results[5])\n",
    "acc_random_forest = metrics.accuracy_score(y_test, results[6])\n",
    "\n",
    "print(\"Acc KNN: {}\".format(acc_knn))\n",
    "print(\"Acc MLP: {}\".format(acc_MLP))\n",
    "print(\"Acc SGDC: {}\".format(acc_SGDC))\n",
    "print(\"Acc svm: {}\".format(acc_svm))\n",
    "print(\"Acc decision_tree: {}\".format(acc_decision_tree))\n",
    "print(\"Acc naive_bayes: {}\".format(acc_naive_bayes))\n",
    "print(\"Acc random_forest: {}\".format(acc_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7296f",
   "metadata": {},
   "source": [
    "VP = Verdadeiro positivo - objeto pertence a classe A e foi classificado na classe A\n",
    "\n",
    "VN = Verdadeiro negativo - objeto não pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "FP = Falso positivo - objeto não pertence a classe A e foi classificado na classe A\n",
    "\n",
    "FN = Falso negativo - objeto pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "A sensibilidade/revocação/recall do classificador, por classe,  pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "520155f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "precision KNN: [0.72619048 0.73684211 0.85393258 0.96261682]\n",
      "precision MLP: [0.76829268 0.75       0.87012987 0.99056604]\n",
      "precision SGDC: [0.73563218 0.72307692 0.87179487 0.98130841]\n",
      "precision svm: [0.74117647 0.75862069 0.87209302 0.98148148]\n",
      "precision decision_tree: [0.71910112 0.77777778 0.79487179 0.96261682]\n",
      "precision naive_bayes: [0.5952381  0.825      0.83606557 0.93636364]\n",
      "precision random_forest: [0.74       0.93333333 0.85714286 0.98148148]\n",
      "recall\n",
      "precision KNN: [0.74390244 0.62686567 0.96202532 0.94495413]\n",
      "precision MLP: [0.76829268 0.80597015 0.84810127 0.96330275]\n",
      "precision SGDC: [0.7804878  0.70149254 0.86075949 0.96330275]\n",
      "precision svm: [0.76829268 0.65671642 0.94936709 0.97247706]\n",
      "precision decision_tree: [0.7804878  0.73134328 0.78481013 0.94495413]\n",
      "precision naive_bayes: [0.91463415 0.49253731 0.64556962 0.94495413]\n",
      "precision random_forest: [0.90243902 0.62686567 0.91139241 0.97247706]\n",
      "f1_score\n",
      "precision KNN: [0.73493976 0.67741935 0.9047619  0.9537037 ]\n",
      "precision MLP: [0.76829268 0.77697842 0.85897436 0.97674419]\n",
      "precision SGDC: [0.75739645 0.71212121 0.86624204 0.97222222]\n",
      "precision svm: [0.75449102 0.704      0.90909091 0.97695853]\n",
      "precision decision_tree: [0.74853801 0.75384615 0.78980892 0.9537037 ]\n",
      "precision naive_bayes: [0.72115385 0.61682243 0.72857143 0.94063927]\n",
      "precision random_forest: [0.81318681 0.75       0.88343558 0.97695853]\n"
     ]
    }
   ],
   "source": [
    "modelo = [\"KNN\", \"MLP\", \"SGDC\", \"svm\", \"decision_tree\", \"naive_bayes\", \"random_forest\"]\n",
    "\n",
    "def precision(y_test, results):\n",
    "    return metrics.precision_score(y_test, results, average=None)\n",
    "def recall(y_test, results):\n",
    "    return metrics.recall_score(y_test, results, average=None)\n",
    "def f1_score(y_test, results):\n",
    "    return metrics.f1_score(y_test, results, average=None)\n",
    "\n",
    "def printScore(modelo, avali):\n",
    "    for i in range(0, len(modelo)):\n",
    "        print(\"precision {}: {}\".format(modelo[i], avali(y_test, results[i])))\n",
    "\n",
    "print(\"Precision\")\n",
    "printScore(modelo, precision)\n",
    "print(\"recall\")\n",
    "printScore(modelo, recall)\n",
    "print(\"f1_score\")\n",
    "printScore(modelo, f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
